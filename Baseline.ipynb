{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24842,
     "status": "ok",
     "timestamp": 1642011404993,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "rNum4AAuVvpZ",
    "outputId": "b874a66a-8a3d-4852-b768-0ec1898ae7e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at drive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##### UNCOMMENT #####\n",
    "# from google.colab import drive\n",
    "# drive.mount('drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LksnpqE24Kpi"
   },
   "source": [
    "# Chargement données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99FDGYXEWDvd"
   },
   "outputs": [],
   "source": [
    "# import re #Regular expressions operation\n",
    "\n",
    "def readFile(filename):\n",
    "    return [line.strip() for line in open(filename)]\n",
    "#.decode(\"utf-8\")\n",
    "\n",
    "def readFileWithChunks(filename):\n",
    "    lines_marked = [line.strip() for line in open(filename)]\n",
    "    # .decode(\"utf-8\")\n",
    "    lines_clean1 = [line.replace('[ ', \"\") for line in lines_marked]\n",
    "    lines_clean2 = [line.replace(' ]', \"\") for line in lines_clean1]\n",
    "    return lines_clean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZgTIdJUi4M5L"
   },
   "outputs": [],
   "source": [
    "path_headline1_chunked = '/content/drive/MyDrive/CENTRALE MARSEILLE/3A/PSTALN/Projet PSTALN/Downloaded files/train_2015_10_22.utf-8/STSint.input.headlines.sent1.chunk.txt'\n",
    "path_headline2_chunked = '/content/drive/MyDrive/CENTRALE MARSEILLE/3A/PSTALN/Projet PSTALN/Downloaded files/train_2015_10_22.utf-8/STSint.input.headlines.sent2.chunk.txt'\n",
    "path_headline1 = '/content/drive/MyDrive/CENTRALE MARSEILLE/3A/PSTALN/Projet PSTALN/Downloaded files/train_2015_10_22.utf-8/STSint.input.headlines.sent1.txt'\n",
    "path_headline2 = '/content/drive/MyDrive/CENTRALE MARSEILLE/3A/PSTALN/Projet PSTALN/Downloaded files/train_2015_10_22.utf-8/STSint.input.headlines.sent2.txt'\n",
    "\n",
    "\n",
    "sent1_lines = readFileWithChunks(path_headline1_chunked)\n",
    "sent2_lines = readFileWithChunks(path_headline2_chunked)\n",
    "sent1_lines_chunked = readFile(path_headline1_chunked)\n",
    "sent2_lines_chunked = readFile(path_headline2_chunked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpUs6AEc43fn"
   },
   "source": [
    "Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1642011407292,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "_tsh4zcF43HW",
    "outputId": "b0ddb0e7-d8c6-4bef-a966-ebe65a96998c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 756\n",
      "Test size: 756\n"
     ]
    }
   ],
   "source": [
    "trainSamples = sent1_lines\n",
    "trainSamplesChunked = sent1_lines_chunked\n",
    "\n",
    "testSamples = sent2_lines\n",
    "testSamplesChunked = sent2_lines_chunked\n",
    "\n",
    "print('Train size:', len(trainSamples))\n",
    "print('Test size:', len(testSamples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzND6A7ziOfC"
   },
   "source": [
    "# Embeddings\n",
    "\n",
    "Chargement d'Embeddings préentrainés de type GloVe pour obtenir des représentation des mots de notre dataset\n",
    "\n",
    "Inspiré de : https://keras.io/examples/nlp/pretrained_word_embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TRXOEVkB7nBw"
   },
   "outputs": [],
   "source": [
    "#On suppose que l'embedding est disponible (voire préentrainé si possible) : cf Mouss\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjM4R4o9UGiR"
   },
   "source": [
    "Creation vocabulaire indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3dbf0JDnUIp4"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(trainSamples).batch(128)\n",
    "vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1642011410351,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "i5qV8cFYU4nK",
    "outputId": "f4b5d42c-4061-49d5-d19f-3c5fdaae5ca1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'in', 'to', 'on']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1642011410352,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "XJXhykbkU8gD",
    "outputId": "6cf9c81f-7b83-46a3-800f-c7a8585304a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17,  1,  1,  4, 17,  1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = vectorizer([[\"the cat sat on the mat\"]])\n",
    "output.numpy()[0, :6]\n",
    "#Dans cette phrase test : 3 mots ne font pas partie du voc de notre db et sont donc '<UNK>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UlhgWvL4VOxd"
   },
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70KnPXjEQbmR"
   },
   "source": [
    "Download GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 185052,
     "status": "ok",
     "timestamp": 1642011595388,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "GXIKaoUDQeHt",
    "outputId": "a65709c5-e784-4a76-d312-e0f4b286a3a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-01-12 18:16:50--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2022-01-12 18:16:50--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2022-01-12 18:16:50--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  5.17MB/s    in 2m 40s  \n",
      "\n",
      "2022-01-12 18:19:30 (5.15 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10975,
     "status": "ok",
     "timestamp": 1642011606347,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "2YBsm3snRISU",
    "outputId": "247f77de-1a0e-4843-cd62-980e34857f0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "path_to_glove_file = '/content/glove.6B.100d.txt'\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1642011606349,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "GYHB-aRoRLWM",
    "outputId": "617cc9ff-43a0-4851-d4a7-af28032017e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 2075 words (58 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EN3_Qiv17k1t"
   },
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaNiMAa3ZJA-"
   },
   "source": [
    "#### Preprocessing\n",
    "\n",
    "> y_train / y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKFuTJsBMoBR"
   },
   "outputs": [],
   "source": [
    "nbClasses = 3 #3 pourBIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEM-Bn35QtQ9"
   },
   "source": [
    "##### Y - BIO Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJ3WhMTNhxj7"
   },
   "outputs": [],
   "source": [
    "def removeNoise(line):\n",
    "    noiseTokens = ['[', ']', ',', '.', ':', ';', '\"', \"'\", \"''\", \"`\", \"-\",]\n",
    "    for token in noiseTokens:\n",
    "      line = line.replace(token, \"\")\n",
    "    return line\n",
    "\n",
    "\n",
    "def chunkedLine2ListChunks(line):\n",
    "  line = removeNoise(line)\n",
    "  line = line.split('  ')\n",
    "  for chunk in line:\n",
    "    if len(chunk)==0: \n",
    "      while chunk in line:\n",
    "        del line[line.index(chunk)]\n",
    "  return line\n",
    "\n",
    "\n",
    "def isInsideChunk(word, chunk):\n",
    "  \"\"\"\n",
    "  Returns True if word have to be encoded as a O (BIO)\n",
    "  Else False\n",
    "  \"\"\"\n",
    "  return word in chunk\n",
    "\n",
    "# ex = sent1_lines_chunked[0]\n",
    "# l = chunkedLine2ListChunks(ex)\n",
    "# print(\"Nazi\" in l[0])\n",
    "# print(isInsideChunk(\"Nazi\", l[0]))\n",
    "\n",
    "\n",
    "def isFirstChunkWord(word, chunk):\n",
    "  \"\"\"\n",
    "  On suppose que le mot est présent dans le chunk\n",
    "\n",
    "  Returns True if word have to be encoded as a B (BIO)\n",
    "  Else False if word have to be encoded as a I (BIO)\n",
    "  \"\"\"\n",
    "  chunk = chunk.split()\n",
    "  return chunk[0] == word\n",
    "\n",
    "# isFirstChunkWord(\"Nazi\", l[0])\n",
    "\n",
    "def wordBIOencoding(word, chunk):\n",
    "  if isInsideChunk(word, chunk):\n",
    "    if isFirstChunkWord(word, chunk): return 'B'\n",
    "    else : return 'I'\n",
    "  else : return 'O'\n",
    "\n",
    "def sentenceBIOencoding(line, chunkedLine):\n",
    "  '''\n",
    "  La pertinence du 'O' n'est pas évidente ici étant donné que tous les mots de line semblent faire partie d'un chunk de chunkedLine\n",
    "  '''\n",
    "\n",
    "  words = line.split()\n",
    "  chunks = chunkedLine2ListChunks(chunkedLine)\n",
    "  BIOcodes = []\n",
    "\n",
    "  currentChunk = 0\n",
    "\n",
    "  for word in words:\n",
    "    code = wordBIOencoding(word, chunks[currentChunk])\n",
    "\n",
    "    if code == 'O':\n",
    "      if currentChunk+1<len(chunks):\n",
    "        currentChunk+=1 #Attention on explore le chunk suivant (si jamais c'est le début d'un autre chunk)\n",
    "        test_code = wordBIOencoding(word, chunks[currentChunk])\n",
    "        if test_code == 'B':\n",
    "          code = test_code\n",
    "\n",
    "    BIOcodes.append(code)\n",
    "  return BIOcodes\n",
    "\n",
    "\n",
    "# for idx in range(3):\n",
    "#   ex = sent1_lines_chunked[idx]\n",
    "#   print(ex)\n",
    "#   l = chunkedLine2ListChunks(ex)\n",
    "#   print(l)\n",
    "#   print()\n",
    "\n",
    "\n",
    "# nbSamples = 3 #len(sent1_lines)\n",
    "# for line, chunkedLine in zip(sent1_lines[:nbSamples], sent1_lines_chunked[:nbSamples]):\n",
    "#   BIOcodes = sentenceBIOencoding(line, chunkedLine)\n",
    "#   print(line.split())\n",
    "#   print(BIOcodes)\n",
    "#   print(chunkedLine)\n",
    "#   print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1642011606370,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "d11QAAaTSzlh",
    "outputId": "487b28f0-d491-4b7d-8542-82dc91e2c1d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756 756\n",
      "[ Former Nazi death camp guard Demjanjuk ] [ dead ] [ at 91 ]\n",
      "['B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I']\n"
     ]
    }
   ],
   "source": [
    "BIO_y_train = []  #Contains BIO codes\n",
    "BIO_y_test = []\n",
    "\n",
    "nbSamples = len(trainSamples)\n",
    "for line, chunkedLine in zip(trainSamples[:nbSamples], trainSamplesChunked[:nbSamples]):\n",
    "    BIOcodes = sentenceBIOencoding(line, chunkedLine)\n",
    "    BIO_y_train.append(BIOcodes)\n",
    "\n",
    "nbSamples = len(testSamples)\n",
    "for line, chunkedLine in zip(testSamples[:nbSamples], testSamplesChunked[:nbSamples]):\n",
    "    BIOcodes = sentenceBIOencoding(line, chunkedLine)\n",
    "    BIO_y_test.append(BIOcodes)\n",
    "\n",
    "print(len(trainSamples), len(BIO_y_train))\n",
    "print(trainSamplesChunked[0])\n",
    "print(BIO_y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6rKpdbdSq8p"
   },
   "source": [
    "##### Y - Conversion caractères BIO en entiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1642011606371,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "S6PlUUGVS3Nr",
    "outputId": "12e85c3f-b61d-4daa-8ac1-390e09b72621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "labelEncoder.fit(['B', 'I', 'O'])\n",
    "print(labelEncoder.transform(['B', 'I', 'O']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1642011606734,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "sFSa_hKN1ISv",
    "outputId": "fc2eb2c9-f660-4d20-98d8-6c7b26fc7117"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Former Nazi death camp guard Demjanjuk ] [ dead ] [ at 91 ]\n",
      "['B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I']\n",
      "[0 1 1 1 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "BIO_int_y_train = []\n",
    "BIO_int_y_test = []\n",
    "\n",
    "for line in BIO_y_train:\n",
    "  BIO_int_y_train.append(labelEncoder.transform(np.array(line)))\n",
    "\n",
    "for line in BIO_y_test:\n",
    "  BIO_int_y_test.append(labelEncoder.transform(np.array(line)))\n",
    "\n",
    "print(trainSamplesChunked[0])\n",
    "print(BIO_y_train[0])\n",
    "print(BIO_int_y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2c872Ewr2a7d"
   },
   "source": [
    "##### Y - Conservion One Hot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1642011606735,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "xvFeLmWg0W03",
    "outputId": "c5e6f977-7f3f-42eb-b14e-e46530f5e3bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Former Nazi death camp guard Demjanjuk ] [ dead ] [ at 91 ]\n",
      "['B', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'I']\n",
      "[0 1 1 1 1 1 0 0 1]\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "y_train = []  #One hot encoded\n",
    "y_test = []\n",
    "\n",
    "for line in BIO_int_y_train:\n",
    "  y_train.append(np_utils.to_categorical(line, num_classes=nbClasses))\n",
    "\n",
    "for line in BIO_int_y_test:\n",
    "  y_test.append(np_utils.to_categorical(line, num_classes=nbClasses))\n",
    "\n",
    "print(trainSamplesChunked[0])\n",
    "print(BIO_y_train[0])\n",
    "print(BIO_int_y_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWijycYa_TDK"
   },
   "source": [
    "##### X - Conversion format input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1642011606736,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "NNs7C1OF_Yg7",
    "outputId": "53425ebf-2b71-4178-bc4e-aec396cbb8f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(756, 200)\n",
      "(756, 200)\n"
     ]
    }
   ],
   "source": [
    "def preprocessLines(lines):\n",
    "  return np.array(vectorizer(np.array([[s] for s in lines])))\n",
    "\n",
    "x_train = preprocessLines(trainSamples)\n",
    "x_test = preprocessLines(testSamples)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCoRbhpbbL6l"
   },
   "source": [
    "##### Y - Conversion format input\n",
    "\n",
    "> On complète le nombre de prédictions attendues pour en avoir le même nombre que de môts dans un sample de X (paddings INCLUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1642011606737,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "QC3FCv8z_erE",
    "outputId": "7d0fd450-49c6-4c22-9903-89cc4855d1f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3)\n"
     ]
    }
   ],
   "source": [
    "predictionForPaddingWord = [0, 0, 2]  # = 'O'\n",
    "lenSentence = x_train.shape[1]\n",
    "\n",
    "def completeLineLabels(lineLabels, lenSentence):\n",
    "  '''\n",
    "  Add 'O' labels for Padding words\n",
    "  '''\n",
    "  nbWordsInSample = len(lineLabels)\n",
    "  nbPaddingLabelsToAdd = lenSentence-nbWordsInSample\n",
    "\n",
    "  paddingLabels = np.array([predictionForPaddingWord for i in range(nbPaddingLabelsToAdd)])\n",
    "  lineLabels = np.concatenate((lineLabels,paddingLabels))\n",
    "\n",
    "  return lineLabels\n",
    "\n",
    "#Test\n",
    "y = np.array(completeLineLabels(y_train[0], 200))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 290,
     "status": "ok",
     "timestamp": 1642011607017,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "SvkhLr2KBmrw",
    "outputId": "7b36d85c-99de-42b9-9fb0-f938ac469bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(756, 200, 3)\n",
      "Sample size (200, 3)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array([np.array(completeLineLabels(line_labels, lenSentence)) for line_labels in y_train])\n",
    "y_test = np.array([np.array(completeLineLabels(line_labels, lenSentence)) for line_labels in y_test])\n",
    "\n",
    "print(y_train.shape)\n",
    "print(\"Sample size\", y_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zppkWKJ4iTHH"
   },
   "source": [
    "#### Modèle tagging : Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1642011607312,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "bwleqItMiaC2",
    "outputId": "eb5ba2e8-4fb5-45a6-e987-aacc723a4385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         213500    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, None, 3)           312       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,812\n",
      "Trainable params: 312\n",
      "Non-trainable params: 213,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Embedding, Input\n",
    "\n",
    "# SimpleRNN model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(None,), dtype=\"int64\"))\n",
    "model.add(Embedding(\n",
    "    input_dim=num_tokens, #Size of the vocabulary\n",
    "    output_dim=embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False #Don't want to update embeddings\n",
    "                    ))\n",
    "model.add(SimpleRNN(units=nbClasses, #dim hidden state returned\n",
    "                    activation=\"softmax\", \n",
    "                    return_sequences=True\n",
    "                    )) #return_sequences=False pour obtenir uniquement la derniere couche RNN\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W46wguvq0JpX"
   },
   "source": [
    "Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 82950,
     "status": "ok",
     "timestamp": 1642011690244,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "HHcTOcLmW5CD",
    "outputId": "0a25b0ca-8ebe-4c2c-e586-6c51e3691492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "24/24 - 3s - loss: 2.0783 - acc: 0.0136 - val_loss: 2.0102 - val_acc: 0.0170 - 3s/epoch - 110ms/step\n",
      "Epoch 2/50\n",
      "24/24 - 1s - loss: 1.9605 - acc: 0.0203 - val_loss: 1.9057 - val_acc: 0.0245 - 1s/epoch - 48ms/step\n",
      "Epoch 3/50\n",
      "24/24 - 1s - loss: 1.8592 - acc: 0.6969 - val_loss: 1.8079 - val_acc: 0.9801 - 1s/epoch - 49ms/step\n",
      "Epoch 4/50\n",
      "24/24 - 1s - loss: 1.7632 - acc: 0.9818 - val_loss: 1.7143 - val_acc: 0.9813 - 1s/epoch - 48ms/step\n",
      "Epoch 5/50\n",
      "24/24 - 1s - loss: 1.6710 - acc: 0.9831 - val_loss: 1.6243 - val_acc: 0.9819 - 1s/epoch - 48ms/step\n",
      "Epoch 6/50\n",
      "24/24 - 1s - loss: 1.5823 - acc: 0.9840 - val_loss: 1.5377 - val_acc: 0.9827 - 1s/epoch - 48ms/step\n",
      "Epoch 7/50\n",
      "24/24 - 1s - loss: 1.4968 - acc: 0.9848 - val_loss: 1.4542 - val_acc: 0.9831 - 1s/epoch - 48ms/step\n",
      "Epoch 8/50\n",
      "24/24 - 1s - loss: 1.4145 - acc: 0.9853 - val_loss: 1.3739 - val_acc: 0.9833 - 1s/epoch - 49ms/step\n",
      "Epoch 9/50\n",
      "24/24 - 1s - loss: 1.3354 - acc: 0.9855 - val_loss: 1.2967 - val_acc: 0.9834 - 1s/epoch - 48ms/step\n",
      "Epoch 10/50\n",
      "24/24 - 1s - loss: 1.2594 - acc: 0.9857 - val_loss: 1.2226 - val_acc: 0.9834 - 1s/epoch - 49ms/step\n",
      "Epoch 11/50\n",
      "24/24 - 1s - loss: 1.1864 - acc: 0.9859 - val_loss: 1.1515 - val_acc: 0.9834 - 1s/epoch - 47ms/step\n",
      "Epoch 12/50\n",
      "24/24 - 1s - loss: 1.1165 - acc: 0.9861 - val_loss: 1.0834 - val_acc: 0.9832 - 1s/epoch - 47ms/step\n",
      "Epoch 13/50\n",
      "24/24 - 1s - loss: 1.0496 - acc: 0.9862 - val_loss: 1.0184 - val_acc: 0.9832 - 1s/epoch - 47ms/step\n",
      "Epoch 14/50\n",
      "24/24 - 1s - loss: 0.9856 - acc: 0.9863 - val_loss: 0.9562 - val_acc: 0.9834 - 1s/epoch - 47ms/step\n",
      "Epoch 15/50\n",
      "24/24 - 1s - loss: 0.9246 - acc: 0.9865 - val_loss: 0.8970 - val_acc: 0.9834 - 1s/epoch - 48ms/step\n",
      "Epoch 16/50\n",
      "24/24 - 1s - loss: 0.8664 - acc: 0.9865 - val_loss: 0.8406 - val_acc: 0.9834 - 1s/epoch - 47ms/step\n",
      "Epoch 17/50\n",
      "24/24 - 1s - loss: 0.8111 - acc: 0.9866 - val_loss: 0.7870 - val_acc: 0.9835 - 1s/epoch - 48ms/step\n",
      "Epoch 18/50\n",
      "24/24 - 1s - loss: 0.7586 - acc: 0.9865 - val_loss: 0.7362 - val_acc: 0.9836 - 1s/epoch - 48ms/step\n",
      "Epoch 19/50\n",
      "24/24 - 1s - loss: 0.7088 - acc: 0.9865 - val_loss: 0.6881 - val_acc: 0.9836 - 1s/epoch - 47ms/step\n",
      "Epoch 20/50\n",
      "24/24 - 1s - loss: 0.6617 - acc: 0.9866 - val_loss: 0.6427 - val_acc: 0.9836 - 1s/epoch - 48ms/step\n",
      "Epoch 21/50\n",
      "24/24 - 1s - loss: 0.6173 - acc: 0.9865 - val_loss: 0.5999 - val_acc: 0.9836 - 1s/epoch - 47ms/step\n",
      "Epoch 22/50\n",
      "24/24 - 1s - loss: 0.5754 - acc: 0.9865 - val_loss: 0.5595 - val_acc: 0.9835 - 1s/epoch - 48ms/step\n",
      "Epoch 23/50\n",
      "24/24 - 1s - loss: 0.5359 - acc: 0.9865 - val_loss: 0.5217 - val_acc: 0.9836 - 1s/epoch - 48ms/step\n",
      "Epoch 24/50\n",
      "24/24 - 1s - loss: 0.4989 - acc: 0.9864 - val_loss: 0.4861 - val_acc: 0.9834 - 1s/epoch - 47ms/step\n",
      "Epoch 25/50\n",
      "24/24 - 1s - loss: 0.4641 - acc: 0.9864 - val_loss: 0.4529 - val_acc: 0.9834 - 1s/epoch - 48ms/step\n",
      "Epoch 26/50\n",
      "24/24 - 1s - loss: 0.4316 - acc: 0.9863 - val_loss: 0.4218 - val_acc: 0.9833 - 1s/epoch - 47ms/step\n",
      "Epoch 27/50\n",
      "24/24 - 1s - loss: 0.4013 - acc: 0.9863 - val_loss: 0.3928 - val_acc: 0.9833 - 1s/epoch - 49ms/step\n",
      "Epoch 28/50\n",
      "24/24 - 1s - loss: 0.3729 - acc: 0.9862 - val_loss: 0.3658 - val_acc: 0.9833 - 1s/epoch - 48ms/step\n",
      "Epoch 29/50\n",
      "24/24 - 1s - loss: 0.3466 - acc: 0.9862 - val_loss: 0.3407 - val_acc: 0.9832 - 1s/epoch - 48ms/step\n",
      "Epoch 30/50\n",
      "24/24 - 1s - loss: 0.3221 - acc: 0.9860 - val_loss: 0.3175 - val_acc: 0.9831 - 1s/epoch - 48ms/step\n",
      "Epoch 31/50\n",
      "24/24 - 1s - loss: 0.2993 - acc: 0.9861 - val_loss: 0.2959 - val_acc: 0.9831 - 1s/epoch - 47ms/step\n",
      "Epoch 32/50\n",
      "24/24 - 1s - loss: 0.2782 - acc: 0.9860 - val_loss: 0.2760 - val_acc: 0.9830 - 1s/epoch - 47ms/step\n",
      "Epoch 33/50\n",
      "24/24 - 1s - loss: 0.2587 - acc: 0.9860 - val_loss: 0.2576 - val_acc: 0.9830 - 1s/epoch - 48ms/step\n",
      "Epoch 34/50\n",
      "24/24 - 1s - loss: 0.2407 - acc: 0.9859 - val_loss: 0.2406 - val_acc: 0.9831 - 1s/epoch - 47ms/step\n",
      "Epoch 35/50\n",
      "24/24 - 1s - loss: 0.2241 - acc: 0.9860 - val_loss: 0.2249 - val_acc: 0.9829 - 1s/epoch - 48ms/step\n",
      "Epoch 36/50\n",
      "24/24 - 1s - loss: 0.2087 - acc: 0.9858 - val_loss: 0.2106 - val_acc: 0.9830 - 1s/epoch - 48ms/step\n",
      "Epoch 37/50\n",
      "24/24 - 1s - loss: 0.1946 - acc: 0.9859 - val_loss: 0.1973 - val_acc: 0.9829 - 1s/epoch - 48ms/step\n",
      "Epoch 38/50\n",
      "24/24 - 1s - loss: 0.1816 - acc: 0.9858 - val_loss: 0.1852 - val_acc: 0.9828 - 1s/epoch - 47ms/step\n",
      "Epoch 39/50\n",
      "24/24 - 1s - loss: 0.1697 - acc: 0.9857 - val_loss: 0.1741 - val_acc: 0.9828 - 1s/epoch - 47ms/step\n",
      "Epoch 40/50\n",
      "24/24 - 1s - loss: 0.1587 - acc: 0.9858 - val_loss: 0.1639 - val_acc: 0.9828 - 1s/epoch - 48ms/step\n",
      "Epoch 41/50\n",
      "24/24 - 1s - loss: 0.1486 - acc: 0.9857 - val_loss: 0.1546 - val_acc: 0.9828 - 1s/epoch - 48ms/step\n",
      "Epoch 42/50\n",
      "24/24 - 1s - loss: 0.1394 - acc: 0.9857 - val_loss: 0.1460 - val_acc: 0.9829 - 1s/epoch - 48ms/step\n",
      "Epoch 43/50\n",
      "24/24 - 1s - loss: 0.1309 - acc: 0.9858 - val_loss: 0.1382 - val_acc: 0.9830 - 1s/epoch - 48ms/step\n",
      "Epoch 44/50\n",
      "24/24 - 1s - loss: 0.1231 - acc: 0.9858 - val_loss: 0.1311 - val_acc: 0.9829 - 1s/epoch - 48ms/step\n",
      "Epoch 45/50\n",
      "24/24 - 1s - loss: 0.1160 - acc: 0.9858 - val_loss: 0.1245 - val_acc: 0.9830 - 1s/epoch - 48ms/step\n",
      "Epoch 46/50\n",
      "24/24 - 1s - loss: 0.1095 - acc: 0.9859 - val_loss: 0.1185 - val_acc: 0.9830 - 1s/epoch - 47ms/step\n",
      "Epoch 47/50\n",
      "24/24 - 1s - loss: 0.1035 - acc: 0.9859 - val_loss: 0.1130 - val_acc: 0.9829 - 1s/epoch - 47ms/step\n",
      "Epoch 48/50\n",
      "24/24 - 1s - loss: 0.0980 - acc: 0.9860 - val_loss: 0.1080 - val_acc: 0.9831 - 1s/epoch - 47ms/step\n",
      "Epoch 49/50\n",
      "24/24 - 1s - loss: 0.0930 - acc: 0.9860 - val_loss: 0.1033 - val_acc: 0.9832 - 1s/epoch - 48ms/step\n",
      "Epoch 50/50\n",
      "24/24 - 1s - loss: 0.0883 - acc: 0.9861 - val_loss: 0.0991 - val_acc: 0.9832 - 1s/epoch - 48ms/step\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=32, verbose=2, validation_data=(x_test, y_test), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "executionInfo": {
     "elapsed": 643,
     "status": "ok",
     "timestamp": 1642011690864,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "cvXgjigYpPb6",
    "outputId": "95a6ad34-7cb8-45e8-9abb-750aee4af81a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8f-3YibuCw2"
   },
   "source": [
    "**Remarque:** Il nous faudrait probablement moins entrainer le modèle afin qu'il se préoccupe moins de la prédiction des paddings en fin de phrase.\n",
    "\n",
    "La moindre prise en compte des paddings en fin de phrase par le modèle est un des problèmes à résoudre ici si l'on souhaite améliorer les performances de ce modèle baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPZI5DHqU2hm"
   },
   "source": [
    "#### 📌 Construction de phrases 'chunkées' à partir de phrases non-chunkées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PewUU3wCU83g"
   },
   "outputs": [],
   "source": [
    "def startChunk(word):\n",
    "  return '[ ' + word\n",
    "\n",
    "def endChunk(word):\n",
    "  return word + ' ]'\n",
    "\n",
    "def chunkLine(line, line_labels_integers, showErrors):\n",
    "\n",
    "  new_line = line.split()\n",
    "  previous_label = -1\n",
    "\n",
    "  i = -1\n",
    "  for word, label in zip(\n",
    "                        line.split(),\n",
    "                        line_labels_integers[:len(line.split())]\n",
    "                        ):\n",
    "    i +=1\n",
    "    if label == 0:  #\"B\"\n",
    "      new_line[i] = startChunk(word)\n",
    "      if previous_label == 1 or previous_label == 0:\n",
    "        new_line[i-1] = endChunk(new_line[i-1])\n",
    "      previous_label = 0\n",
    "\n",
    "    if label == 2:  #'O'\n",
    "      if previous_label == 0 or previous_label== 1:\n",
    "        new_line[i-1] = endChunk(new_line[i-1])\n",
    "      previous_label = 2\n",
    "\n",
    "    if label == 1 : #'I'\n",
    "      if previous_label == 2: \n",
    "        if showErrors : print(f\"Oups il y a eu une erreur de classification du mot '{word}' dans la phrase \\n {line}\\n\")\n",
    "      if previous_label == -1:  #Problème de prédiction d'un I en début de phrase pour des noms propres ...\n",
    "        if showErrors : print(f\"Erreur début de phrase : '{word}'\\n {line}\\n\")\n",
    "        new_line[i] = startChunk(word) \n",
    "      previous_label = 1\n",
    "\n",
    "    if i == len(line.split()) - 1:  #Fin de phrase\n",
    "      if label == 0 or label == 1: # 'B' ou 'I'\n",
    "        new_line[i] = endChunk(word)\n",
    "    \n",
    "  separator = ' '\n",
    "  new_line = separator.join(new_line)\n",
    "  return new_line\n",
    "\n",
    "def chunkDataset(lines, showErrors=False):\n",
    "\n",
    "  #Preprocess 'lines' pour prédictions\n",
    "  x= preprocessLines(lines)\n",
    "\n",
    "  y_pred = model.predict(x)\n",
    "  lines_labels_integers = np.argmax(y_pred, axis=2)\n",
    "\n",
    "  chunkedLines = []\n",
    "\n",
    "  for line, line_labels_integers in zip(lines, lines_labels_integers):\n",
    "    chunkedLines.append(chunkLine(line, line_labels_integers, showErrors))\n",
    "\n",
    "  return chunkedLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 988,
     "status": "ok",
     "timestamp": 1642011692651,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "HOIZiVkvcsmg",
    "outputId": "2f11db26-a81f-4640-ca7d-ca8008242d96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line : \t\t\t\t John Demjanjuk , convicted Nazi death camp guard , dies aged 91\n",
      "True chunked line : \t\t [ John Demjanjuk ] [ , ] [ convicted Nazi death camp guard ] [ , ] [ dies ] [ aged 91 ]\n",
      "Predicted chunked line : \t [ John ] Demjanjuk [ , convicted ] [ Nazi death camp ] [ guard ] , dies aged 91\n",
      "Predicted labels : \t\t [0 2 0 1 0 1 1 0 2 2 2 2]\n",
      "\n",
      "Line : \t\t\t\t Saudi Women Allowed To Compete At Olympics\n",
      "True chunked line : \t\t [ Saudi Women ] [ Allowed ] [ To Compete ] [ At Olympics ]\n",
      "Predicted chunked line : \t [ Saudi Women ] Allowed [ To ] [ Compete ] [ At Olympics ]\n",
      "Predicted labels : \t\t [0 1 2 0 0 0 1]\n",
      "\n",
      "Line : \t\t\t\t Drone strike kills four suspected militants in Pakistan\n",
      "True chunked line : \t\t [ Drone strike ] [ kills ] [ four suspected militants ] [ in Pakistan ]\n",
      "Predicted chunked line : \t [ Drone strike ] [ kills ] [ four ] [ suspected ] [ militants ] [ in Pakistan ]\n",
      "Predicted labels : \t\t [0 1 0 0 0 0 0 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chunkedLines = chunkDataset(testSamples, showErrors=False)\n",
    "nb = 3\n",
    "\n",
    "#Pour affichage uniquement\n",
    "x= preprocessLines(testSamples)\n",
    "y_pred = model.predict(x)\n",
    "lines_labels_integers = np.argmax(y_pred, axis=2)\n",
    "\n",
    "for line, trueChunkedLine, chunkedLine, lineLabels in zip(testSamples[:nb], testSamplesChunked[:nb], chunkedLines[:nb], lines_labels_integers[:nb]):\n",
    "  print('Line : \\t\\t\\t\\t', line)\n",
    "  print('True chunked line : \\t\\t', trueChunkedLine)\n",
    "  print('Predicted chunked line : \\t', chunkedLine)\n",
    "  print('Predicted labels : \\t\\t', lineLabels[:len(line.split())])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXr0_32J_B1x"
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_JBKgEZiYjN"
   },
   "source": [
    "##### Evaluation par label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GovzKo-DiaWQ"
   },
   "outputs": [],
   "source": [
    "def getBatchAccuracy(y_pred, y_true):\n",
    "  '''\n",
    "  Input\n",
    "  -----\n",
    "  Batch labels hot encoded of dimension batch_size x 200 x 3\n",
    "  '''\n",
    "  assert len(y_pred.shape) == len(y_true.shape) == 3 \n",
    "\n",
    "  sum_acc = 0\n",
    "  for i in range(len(y_pred)):\n",
    "    sum_acc += getSampleAccuracy(y_pred[i], y_true[i])  #Attention ici on ne défini pas une prédiction de chunking de phrase uniquement comme correcte ou non, mais possiblement partiellement correcte\n",
    "  return sum_acc / len(y_pred)\n",
    "\n",
    "\n",
    "def getSampleAccuracy(y_sample_pred, y_sample_true):\n",
    "  '''\n",
    "  Input\n",
    "  -----\n",
    "  Sentence/Sample labels hot encoded of dimension 200 x 3\n",
    "  '''\n",
    "  # assert len(y_sample_pred.shape) == len(y_sample_true.shape) == 2\n",
    "\n",
    "  pred_labels_integers = np.argmax(y_sample_pred, axis=1)\n",
    "  true_labels_integers = np.argmax(y_sample_true, axis=1)\n",
    "\n",
    "  true_counts = 0\n",
    "  insideSentence = False\n",
    "  lenSentence = 0\n",
    "  for i in range(len(pred_labels_integers)-1, -1, -1):\n",
    "\n",
    "    #On ne prend pas en compte les paddings àjoutés à la fin des phrases pour le calcul du score\n",
    "    if (true_labels_integers[i] != 2) and not(insideSentence):\n",
    "      insideSentence = True\n",
    "\n",
    "    if insideSentence: lenSentence += 1\n",
    "    if true_labels_integers[i] == pred_labels_integers[i] and insideSentence:\n",
    "      true_counts +=1\n",
    "  \n",
    "  # if lenSentence !=0 : print(pred_labels_integers)\n",
    "  return true_counts/(lenSentence+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1642011691290,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "k5EqAqXenKnD",
    "outputId": "1c1a0eae-5160-4c24-fd03-5f7deedc1e05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5713044275164956\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_train)\n",
    "\n",
    "acc = getBatchAccuracy(y_pred=y_pred, y_true=y_train)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1642011691668,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "NzqbMuPxUY7v",
    "outputId": "86b71362-a23f-4874-8a3f-d86952dd393c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5124096600783107\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "\n",
    "acc = getBatchAccuracy(y_pred=y_pred, y_true=y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2HNxzgY-y_w"
   },
   "source": [
    "##### Evaluation par chunk\n",
    "\n",
    "Méthode retenue pour la comparaison avec le modèle state of the art.\n",
    "\n",
    "Cette méthode est à nuancer car on considère ici qu'un chunck est soit bon soit faut (et non pas partiellement bon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJm7NFGIY8jx"
   },
   "outputs": [],
   "source": [
    "def chunking_score(output_chunks, gold_chunks):\n",
    "    score = 0\n",
    "    for i in range(len(output_chunks)):\n",
    "        sent_score = 0\n",
    "        for chk in output_chunks[i]:\n",
    "            if chk in gold_chunks[i]:\n",
    "                sent_score += 1\n",
    "        score += sent_score/len(gold_chunks[i])\n",
    "    return score/len(output_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5vESgZmb4pG"
   },
   "outputs": [],
   "source": [
    "def removeWordsOutOfChunks(line):\n",
    "  new_line = []\n",
    "\n",
    "  c = ''  #current chunk\n",
    "  insideChunk = False\n",
    "\n",
    "  for char in line:\n",
    "\n",
    "    if char == ']': \n",
    "      insideChunk = False\n",
    "      new_line.append(c.strip())\n",
    "      c = ''\n",
    "\n",
    "    if insideChunk : c += char\n",
    "\n",
    "    if char == '[': \n",
    "      insideChunk = True\n",
    "\n",
    "\n",
    "  return new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1642012270540,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "yd7oJRa6Y-rg",
    "outputId": "cd6417ea-0d17-4396-9d8b-ce9912990d20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37132096665826797"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_chunks = []\n",
    "gold_chunks = []\n",
    "for true_line, line in zip(testSamplesChunked, chunkedLines):\n",
    "  ## Filtrage des mots : Suppression des mots prédis comme hors des chunks (pour fit la méthode d'évaluation proposée)\n",
    "  newLine = removeWordsOutOfChunks(line)\n",
    "\n",
    "  #Transformation phrase chuckée en liste de chunks\n",
    "  # newLine déja au bon format\n",
    "  gold_chunk = true_line.strip(\"[ \").strip(\" ]\").split(\" ] [ \")\n",
    "\n",
    "  output_chunks.append(newLine)\n",
    "  gold_chunks.append(gold_chunk)\n",
    "\n",
    "#Calculer score\n",
    "chunking_score(output_chunks, gold_chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCnuyPMRSYEG"
   },
   "source": [
    "# Alignement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udgIkrpTTdA7"
   },
   "source": [
    "### Définition des méthodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "701F4RjgTxIE"
   },
   "outputs": [],
   "source": [
    "from math import *\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def norm(x):\n",
    "    norm=0\n",
    "    for elt in x:\n",
    "        norm+=elt**2\n",
    "    norm=sqrt(norm)\n",
    "    return(norm)\n",
    "\n",
    "def similarity(x,y):\n",
    "    '''\n",
    "    Cosine Similarity\n",
    "    '''\n",
    "    sim=np.dot(x, y)\n",
    "    sim=sim/(norm(x)*norm(y))\n",
    "    return(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2if93NkTgH5"
   },
   "source": [
    "Méthode d'alignement : Hungarian Algorithm (a.k.a. the Kuhn-Munkres algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lFMEkA8qTWGT"
   },
   "outputs": [],
   "source": [
    "def alignment_chunks(sentence_1, sentence_2):\n",
    "    '''\n",
    "    Hungarian Algorithm : aligner chunks pour meilleur score possible de phrase \n",
    "\n",
    "    Idea for improvement : \n",
    "    Normalize chunk similarity by number of tokens in shorter chunk \n",
    "    such that it assigned higher scores to pairs of chunks such as physician and general physician.\n",
    "    '''\n",
    "    cost=[]\n",
    "    if len(sentence_2)<len(sentence_1): ##If more rows than columns, not every row needs to be assigned to a column, and vice versa.\n",
    "        s1, s2 = sentence_2, sentence_1 #Always select shorter sentence as first sentence !\n",
    "        inv=True\n",
    "    else:\n",
    "        s1, s2=sentence_1, sentence_2\n",
    "        inv=False\n",
    "\n",
    "    for i in range (len(s1)):\n",
    "        inter=[]\n",
    "        for j in range(len(s2)):\n",
    "            sim=alignment_mots(s1[i], s2[j])        \n",
    "            inter.append(sim)\n",
    "        cost.append(inter)\n",
    "    cost=np.array(cost)\n",
    "\n",
    "    row_ind, col_ind = linear_sum_assignment(-cost) # - car linear_sum_assignment minimise normalement\n",
    "    \n",
    "    #Liste de score de similarité pour chaque alignement optimal de chunks\n",
    "    sim=cost[row_ind, col_ind]\n",
    "    sim=min_max_scaler(sim)\n",
    "\n",
    "    if inv:\n",
    "        row_ind, col_ind=col_ind, row_ind\n",
    "\n",
    "    list_couples_chunks_et_score=[]\n",
    "    for i in range(len(sim)):\n",
    "        list_couples_chunks_et_score.append((row_ind[i], col_ind[i], sim[i]))\n",
    "\n",
    "    return(list_couples_chunks_et_score)\n",
    "\n",
    "\n",
    "def alignment_mots(chunk_1, chunk_2):\n",
    "    '''\n",
    "    Hungarian Algorithm sur 2 chunks : aligner mots pour meilleur score possible\n",
    "    '''\n",
    "    if len(chunk_2)<len(chunk_1): ##If more rows than columns, not every row needs to be assigned to a column, and vice versa.\n",
    "        c1, c2 = chunk_2, chunk_1 #Always select shorter sentence as first sentence !\n",
    "    else:\n",
    "        c1, c2 = chunk_1, chunk_2\n",
    "    cost=[]\n",
    "    for i in range (len(c1)):\n",
    "        inter=[]\n",
    "        for j in range(len(c2)):\n",
    "            inter.append(similarity(c1[i], c2[j]))\n",
    "        cost.append(inter)\n",
    "    cost=np.array(cost)\n",
    "\n",
    "    # print(cost.shape)\n",
    "    # print(chunk_1, chunk_2)\n",
    "    # print()\n",
    "\n",
    "    #col_ind, #col_ind donne alignement des mots pour obtenir meilleur score de similarité possible\n",
    "    row_ind, col_ind = linear_sum_assignment(-cost) #- car linear_sum_assignment minimise normalement\n",
    "    \n",
    "    #score de similarité entre 2 chunks\n",
    "    sim=cost[row_ind, col_ind].sum()\n",
    "\n",
    "    return(sim)\n",
    " \n",
    "\n",
    "def min_max_scaler(sim):\n",
    "    scaled=[]\n",
    "    a, b = 3, 1 #On remarque que les scores non scalés sont tous entre 1 et 3 #np.max(sim), np.min(sim) \n",
    "    \n",
    "    for elt in sim:\n",
    "        inter = (elt-b)/(a-b)\n",
    "        inter = inter*5 #Pour avoir des scores entre 0 et 5\n",
    "        inter = round(inter) #Pour avoir des scores entiers\n",
    "        scaled.append(inter)\n",
    "    return(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNs2oIEYT__G"
   },
   "outputs": [],
   "source": [
    "def create_list_of_embedded_chunks_exploitable_for_alignement(chunked_sentence):\n",
    "  chunk=''\n",
    "\n",
    "  list_sentence=[]\n",
    "  for i in range(len(chunked_sentence)):\n",
    "    elt = chunked_sentence[i]\n",
    "    if elt!='[' or elt !=']' or elt!=' ':\n",
    "      chunk += elt\n",
    "    if elt==']':\n",
    "      chunk = removeNoise(chunk)\n",
    "      list_sentence.append(chunk)\n",
    "      chunk = ''\n",
    "\n",
    "  list_sentence_embedded=[]\n",
    "  for elt in list_sentence:\n",
    "    inter = elt.split(' ')\n",
    "    inter_copy=inter[:] #inter without '\n",
    "\n",
    "    for elt_bis in inter_copy:\n",
    "      if elt_bis=='':\n",
    "        inter_copy.remove(elt_bis)\n",
    "\n",
    "    inter_embedded=[]\n",
    "    for elt_ter in inter_copy:\n",
    "      elt = vectorizer(elt_ter)\n",
    "      elt = elt.numpy()\n",
    "      elt = list(elt)\n",
    "      if len(elt)!=0:\n",
    "        inter_embedded.append(elt)\n",
    "\n",
    "    list_sentence_embedded.append(inter_embedded)\n",
    "\n",
    "  return(list_sentence_embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euTfkt6cayVY"
   },
   "source": [
    "### Tests préliminaires performance algo\n",
    "\n",
    "**Remarque:** Notre algorithme d'alignement de chunks ne fonctionne pas pour certaines phrases et nous n'avons pas trouvé d'explications à celà pour le moment.\n",
    "\n",
    "> Calcul de la proportion de combinaisons de phrases renvoyant un message d'erreur en prenant les 10 premières phrases du corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5149,
     "status": "ok",
     "timestamp": 1642014961503,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "2i8S-DzjSYEH",
    "outputId": "c1189d74-f7d7-410c-bfe5-588dc49b05ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 3, 2), (1, 1, 0), (2, 0, 2), (3, 2, 2)]\n",
      "[(3, 0, 2), (2, 1, 0), (0, 2, 2)]\n",
      "[(0, 4, 2), (1, 2, 0), (2, 3, 2), (3, 1, 0)]\n",
      "[(0, 3, 2), (1, 2, 0), (2, 0, 2), (3, 1, 0)]\n",
      "[(0, 3, 2), (1, 2, 0), (2, 1, 0), (3, 0, 0)]\n",
      "[(3, 0, 2), (1, 1, 0), (2, 2, 5)]\n",
      "[(0, 4, 2), (1, 2, 0), (2, 3, 5), (3, 1, 0)]\n",
      "[(0, 3, 2), (1, 2, 0), (2, 0, 2), (3, 1, 0)]\n",
      "[(0, 1, 0), (1, 2, 0), (2, 3, 5), (3, 0, 0)]\n",
      "[(0, 4, 2), (1, 2, 0), (2, 3, 5)]\n",
      "[(0, 3, 2), (1, 2, 0), (2, 0, 2)]\n",
      "[(0, 1, 0), (1, 2, 0), (2, 3, 5)]\n",
      "[(4, 0, 2), (1, 1, 0), (2, 2, 0), (3, 3, 2)]\n",
      "[(4, 0, 0), (1, 1, 0), (2, 2, 0), (3, 3, 5)]\n",
      "[(0, 3, 2), (1, 2, 0), (2, 1, 0), (3, 0, 0)]\n",
      "0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "n= 10#len(testSamplesChunked)\n",
    "\n",
    "n_failed=0\n",
    "\n",
    "for i in range(n-1):\n",
    "  for j in range(i+1,n):\n",
    "    try:\n",
    "\n",
    "      sentence_1=testSamplesChunked[i]\n",
    "      sentence_2=testSamplesChunked[j]\n",
    "\n",
    "      sentence_a=create_list_of_embedded_chunks_exploitable_for_alignement(sentence_1)\n",
    "      sentence_b=create_list_of_embedded_chunks_exploitable_for_alignement(sentence_2)\n",
    "\n",
    "      print(alignment_chunks(sentence_a, sentence_b))\n",
    "    except:\n",
    "      n_failed+=1\n",
    "      pass\n",
    "\n",
    "nb_couples=n*(n+1)*0.5\n",
    "print(n_failed/nb_couples) #Proportions de combinaisons ne fonctionnant pas m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzKphd8tk0i0"
   },
   "source": [
    "Recherche des chunks alignés avec des scores de similarités égaux à 5 pour étudier les performances de notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YO9W0igMSYEH"
   },
   "outputs": [],
   "source": [
    "n= 100#len(testSamplesChunked)\n",
    "\n",
    "n_failed=0\n",
    "list_best_scores=[]\n",
    "\n",
    "for i in range(1,n-1):\n",
    "  for j in range(i+1,n):\n",
    "    try:\n",
    "\n",
    "      sentence_1=testSamplesChunked[i]\n",
    "      sentence_2=testSamplesChunked[j]\n",
    "\n",
    "      sentence_a=create_list_of_embedded_chunks_exploitable_for_alignement(sentence_1)\n",
    "      sentence_b=create_list_of_embedded_chunks_exploitable_for_alignement(sentence_2)\n",
    "\n",
    "      for elt in alignment_chunks(sentence_a, sentence_b)[:][2]:\n",
    "        if elt==5:\n",
    "          list_best_scores.append((i,j))\n",
    "\n",
    "      #print(alignment_chunks(sentence_a, sentence_b), (i,j))\n",
    "    except:\n",
    "      n_failed+=1\n",
    "      pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Otesl0Yyu1XB"
   },
   "outputs": [],
   "source": [
    "for (i,j) in list_best_scores:\n",
    "    sentence_1=testSamplesChunked[i]\n",
    "    sentence_2=testSamplesChunked[j]\n",
    "\n",
    "    sentence_a=create_list_of_embedded_chunks_exploitable_for_alignement(sentence_1)\n",
    "    sentence_b=create_list_of_embedded_chunks_exploitable_for_alignement(sentence_2)\n",
    "\n",
    "    print(alignment_chunks(sentence_a, sentence_b))\n",
    "    print(sentence_1)\n",
    "    print(sentence_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dd6H3JoolfvL"
   },
   "source": [
    "### Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3X7w6tJWnOxZ"
   },
   "source": [
    "Alignement sur les gold chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 769
    },
    "executionInfo": {
     "elapsed": 549,
     "status": "error",
     "timestamp": 1642014887702,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "DIaBZr-elhXJ",
    "outputId": "8f1c7ac5-f0a0-4857-ec61-341a47d68514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[259, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1291, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [682, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1560, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1749, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [738, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]\n",
      "[[[1453, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1749, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [], [[667, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1291, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [682, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1560, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [], [[50, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [738, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]\n",
      "(2, 6)\n",
      "[[259, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1291, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [682, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1560, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1749, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] [[1453, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1749, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "\n",
      "(0,)\n",
      "[[259, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1291, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [682, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1560, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1749, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] []\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-9456ef3dcdd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mscore_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malignment_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0malignements_gold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-34226fd07207>\u001b[0m in \u001b[0;36malignment_chunks\u001b[0;34m(sentence_1, sentence_2)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0minter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0msim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malignment_mots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0minter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-34226fd07207>\u001b[0m in \u001b[0;36malignment_mots\u001b[0;34m(chunk_1, chunk_2)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m#col_ind, #col_ind donne alignement des mots pour obtenir meilleur score de similarité possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mrow_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_sum_assignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#- car linear_sum_assignment minimise normalement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m#score de similarité entre 2 chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/_lsap.py\u001b[0m in \u001b[0;36mlinear_sum_assignment\u001b[0;34m(cost_matrix, maximize)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         raise ValueError(\"expected a matrix (2-d array), got a %r array\"\n\u001b[0;32m---> 82\u001b[0;31m                          % (cost_matrix.shape,))\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     if not (np.issubdtype(cost_matrix.dtype, np.number) or\n",
      "\u001b[0;31mValueError\u001b[0m: expected a matrix (2-d array), got a (0,) array"
     ]
    }
   ],
   "source": [
    "dataset1_chunked = trainSamplesChunked\n",
    "dataset2_chunked = testSamplesChunked\n",
    "\n",
    "alignements_gold = []\n",
    "for S1, S2 in zip(dataset1_chunked, dataset2_chunked): \n",
    "\n",
    "  #Preprocess\n",
    "  s1 = create_list_of_embedded_chunks_exploitable_for_alignement(S1)\n",
    "  s2 = create_list_of_embedded_chunks_exploitable_for_alignement(S2)\n",
    "\n",
    "  print(s1)\n",
    "  print(s2)\n",
    "\n",
    "  score_line = alignment_chunks(s1, s2)\n",
    "  alignements_gold.append(score_line)\n",
    "\n",
    "#alignements_gold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvBf4zCsnSLi"
   },
   "source": [
    "Alignement sur les chunks prédits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "executionInfo": {
     "elapsed": 942,
     "status": "error",
     "timestamp": 1642015002047,
     "user": {
      "displayName": "William Jonas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07205973325962472450"
     },
     "user_tz": -60
    },
    "id": "Oao7bfxwlheF",
    "outputId": "8a0edaeb-4781-428b-b299-df660a721820"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-64f1439cbd97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_list_of_embedded_chunks_exploitable_for_alignement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mscore_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malignment_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0malignements_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-260fd4abc0e3>\u001b[0m in \u001b[0;36malignment_chunks\u001b[0;34m(sentence_1, sentence_2)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mcost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mrow_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_sum_assignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# - car linear_sum_assignment minimise normalement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#Liste de score de similarité pour chaque alignement optimal de chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/_lsap.py\u001b[0m in \u001b[0;36mlinear_sum_assignment\u001b[0;34m(cost_matrix, maximize)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         raise ValueError(\"expected a matrix (2-d array), got a %r array\"\n\u001b[0;32m---> 82\u001b[0;31m                          % (cost_matrix.shape,))\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     if not (np.issubdtype(cost_matrix.dtype, np.number) or\n",
      "\u001b[0;31mValueError\u001b[0m: expected a matrix (2-d array), got a (0,) array"
     ]
    }
   ],
   "source": [
    "chunkedLines1 = chunkDataset(trainSamples, showErrors=False)\n",
    "chunkedLines2 = chunkDataset(testSamples, showErrors=False)\n",
    "\n",
    "alignements_pred = []\n",
    "for S1, S2 in zip (chunkedLines1, chunkedLines2): \n",
    "\n",
    "  # Suppression des mots hors des chunks avant alignement\n",
    "  s1 = removeWordsOutOfChunks(S1)\n",
    "  s2 = removeWordsOutOfChunks(S2)\n",
    "\n",
    "  #Preprocess\n",
    "  s1 = create_list_of_embedded_chunks_exploitable_for_alignement(s1)\n",
    "  s2 = create_list_of_embedded_chunks_exploitable_for_alignement(s2)\n",
    "\n",
    "  score_line = alignment_chunks(s1, s2)\n",
    "  alignements_pred.append(score_line)\n",
    "\n",
    "# alignements_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqgED7x7P8HY"
   },
   "source": [
    "On crée une fonction permettant de mettre les résultats de l'alignement des segments sous forme d'un fichier .wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MaJ5rK-mP6v0"
   },
   "outputs": [],
   "source": [
    "def enumerate_word_with_indexe(sentence):\n",
    "  list_words=[]\n",
    "  a=sentence.split(']')\n",
    "  counter=1\n",
    "  for i in range(len(a)):\n",
    "    b=a[i]\n",
    "    b=b.replace('[','')\n",
    "    indices=[]\n",
    "    for elt in b.split():\n",
    "      print(counter,'', elt)\n",
    "      indices.append(counter)\n",
    "      counter+=1\n",
    "    list_words.append(b.split()+[indices])\n",
    "  return(list_words)\n",
    "\n",
    "sentence_1=testSamplesChunked[1]\n",
    "sentence_2=testSamplesChunked[2]\n",
    "\n",
    "sentence_a=create_list_of_embedded_chunks_exploitable_for_alignement(sentence_1)\n",
    "sentence_b=create_list_of_embedded_chunks_exploitable_for_alignement(sentence_2)\n",
    "\n",
    "str_liste_indices_token_chunk1, str_liste_indices_token_chunk2, scores=[], [], []\n",
    "for elt in alignment_chunks(sentence_a, sentence_b):\n",
    "  str_liste_indices_token_chunk1.append(elt[0])\n",
    "  str_liste_indices_token_chunk2.append(elt[1])\n",
    "  scores.append(elt[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_aa5mVB_QIWT"
   },
   "outputs": [],
   "source": [
    "#def format_wa(path_to_write, chunked_sentence1, chunked_sentence2):\n",
    "print('<sentence id=\"' + str(id) + '\" status=\"\">')\n",
    "print('// ' + sentence1)\n",
    "print('// ' + sentence2)\n",
    "print('<source>')\n",
    "chunks1=enumerate_word_with_indexe(sentence_1)\n",
    "print('</source>')\n",
    "print('<translation>')\n",
    "chunks2=enumerate_word_with_indexe(sentence_2)\n",
    "print('</translation>')\n",
    "print('<alignment>')\n",
    "for i in range(len(scores)): \n",
    "  a, b=str_liste_indices_token_chunk1[i], str_liste_indices_token_chunk2[i]\n",
    "  print(str(chunks1[a][-1]) + ' <==> ' + str(chunks2[b][-1])\n",
    "      + ' // EQUI // ' + str(scores[i]) + ' // ' + str(chunks1[a][:-1]) + ' <==> ' + str(chunks2[b][:-1]))\n",
    "print('</alignment>')\n",
    "print('</sentence>')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "nzND6A7ziOfC",
    "EaNiMAa3ZJA-",
    "rEM-Bn35QtQ9",
    "Q6rKpdbdSq8p",
    "2c872Ewr2a7d",
    "zppkWKJ4iTHH",
    "T_JBKgEZiYjN",
    "F2HNxzgY-y_w",
    "udgIkrpTTdA7",
    "euTfkt6cayVY"
   ],
   "name": "Baseline",
   "provenance": [
    {
     "file_id": "1AuryuY6IqRlIkNAj4Jdybm7fd4tlri9O",
     "timestamp": 1641931370216
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
