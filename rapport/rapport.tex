% Preamble
\documentclass[a4paper, twoside, 11pt]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[english,french]{babel}
\usepackage[a4paper]{geometry}
\usepackage[affil-it]{authblk}
\usepackage{etoolbox}
\usepackage{lmodern}

%%% Biblio %%%

\AtBeginDocument{\setlength\bibitemsep{0.5\baselineskip}}

\usepackage[
    backend=biber,        % compilateur par défaut pour biblatex
%sorting=nyt,          % trier par nom, année, titre
    style=ieee,
    natbib=true
%bibstyle=alphabetic,  % style de bibliographie alphabétique
]{biblatex}
\addbibresource{biblio.bib}

%%% Options taille police titre/auteurs  %%%
\makeatletter
\patchcmd{\@maketitle}{\LARGE \@title}{\fontsize{16}{19.2}\selectfont\@title}{}{}
\makeatother

\renewcommand\Authfont{\fontsize{12}{14.4}\selectfont}
%\renewcommand\Affilfont{\fontsize{9}{10.8}\itshape}

\title{Structured Prediction for Natural Language Processing}
\author{Fronteau T., Jonas W., Lepetit M., Martzloff A., Mousseaux V.}
%\affil{Aix-Marseille Université}

% Document
\begin{document}

 \maketitle
 \section{Similarité sémantique entre phrases}
    L'objectif de ce projet est d'implémenter et d'évaluer un modèle à l’état de l’art pour résoudre une tâche de similarité textuelle sémantique (STS).

    \subsection{Description de la tâche}

        \subsubsection{Campagne d’évaluation SEMEVAL}

    Les campagnes SEMEVAL sont organisées tous les ans et regroupent plusieurs défis en lien avec la représentation du sens du texte. La tâche Interpretable Semantic Textual Similarity a été proposée lors des campagnes d’évaluation SEMEVAL de 2016. Elle consiste à comparer deux phrases en anglais selon leur similarité. Cependant, au lieu de comparer les phrases entières, ici il faut d’abord découper la phrase en segments. En effet, la STS mesure le degré d'équivalence sémantique entre des segments de texte appariés. La STS interprétable (iSTS) quant à elle ajoute une couche explicative. Étant donné des paires de phrases données en entrée, les participants doivent d'abord identifier les segments dans chaque phrase, puis aligner les segments des deux phrases en indiquant la relation et le score de similarité de chaque alignement. Nous nous contenterons d'établir le score de similarité et n'indiquerons donc pas quelle est la relation (équivalence, implication, ...) entre les segments comparables dans les paires de phrases.

        \subsubsection{Approche empirique}

    \paragraph{Identification des fragments}
    \hfill \break
    \textit{En entrée}: deux fichiers. Le premier contient les premières phrases de chaque paire. Le second contient les deuxièmes phrases de chaque paire. \hfill \break
    \textit{En sortie}: deux fichiers. Le premier contient les premières phrases de chaque paire avec des '[' et ']' pour marquer les fragments. Le second contient les deuxièmes phrases de chaque paire avec des '[' et ']' pour marquer les fragments.

 \paragraph{Alignement et score de similarité}
    \hfill \break
    \textit{En entrée}: deux fichiers. Le premier contient les premières phrases de chaque paire avec des '[' et ']' pour marquer les fragments. Le second contient les deuxièmes phrases de chaque paire avec des '[' et ']' pour marquer les fragments. \hfill \break
    \textit{En sortie}: Un fichier .wa (de type xml) qui, pour une ligne par alignement, contient l'indice d'un token de la première phrase d'une paire, l'indice d'un token de la deuxième phrase de la paire et le score de similarité associé.

    \subsection{Cadre}

    Dans la section suivante, nous décrirons les méthodes d'approche et techniques d'apprentissage proposés par la communauté scientifique en réponse à la \og shared task \fg{}.

        \subsubsection{DTSim}

        Après une phase de preprocessing, Banjade et al. \cite{banjade} utilisent un modèle statistique Conditional Random Fields (CRF) pour la création des segments qui permet de prendre en compte les dépendances entre les différentes prédictions. Pour cela, le modèle utilise notamment comme entrée les mots suivant et précédant le mot courant ainsi que la partie de discours de chacun des trois mots.
Les résultats du modèle CRF sont ensuite enrichis par l'ajout de règles qui permettent d'obtenir des segments plus intéressants d'un point de vue lexical. Le test du modèle présenté comparé à deux autres (\textit{OpenNLP Chunk} et O-NLP enrichi avec les règles ci-dessus) montre que le modèle développé a de bien meilleures performances et que l'ajout de règles permet effectivement la création de meilleurs segments.

 Pour l'alignement des segments, Banjade et al. se base sur un autre modèle développé par Banjade et al \cite{banjadeautre} qui utilise un score de similarité entre les mots pour trouver les segments les plus ressemblants. Un alignement est d'abord effectué entre les mots des deux segments pour déterminer leur score de similarité en utilisant la méthode de Kuhn-Munkres puis un second alignement est effectué afin de maximiser le score. Excepté les outils de preprocessing, l'équipe du projet n'utilise pas de modèle de machine learning se privant ainsi d'outils à fortes capacités et prometteurs en traitement du langage.

        \subsubsection{Inspire}

Le système Inspire de Kazmi et Schüller \cite{kazmi} repose sur l'utilisation d'un solveur Answer Set, qui utilise une syntaxe et des règles de programmation logique connues sous le nom de Answer Set Programming (ASP). Dans un premier temps, le découpage en morceaux est effectué en utilisant l'ASP, à partir d'un POS-tagging et d'une analyse syntaxique par transition. Ensuite, l'utilisation d'outils déjà entrainés permet d'associer à chaque morceau des caractéristiques en effectuant un POS-tagging, un NER-tagging, un calcul de similarité entre morceaux à l'aide de Word2Vec, et une recherche de synonymes dans WordNet. Enfin, un ensemble de règles inspirées de NeRoSim terminent de définir le problème ASP, qui est donc résolu sans nécessiter d'apprentissage.

Le système Inspire est dans le top 3 des systèmes présentés lors du concours lorsqu'il s'agit de l'évaluation des bases de données Headlines et Images, mais il est le plus mauvais sur les données Student-Aswers. En effet, le découpage en morceaux du système repose sur une analyse par transition, qui est peu performante dans le cadre de données qui ne sont pas syntaxiquement correctes comme Student-Answers. L'approche du système Inspire apporte la puissance des solveurs d'ASP au set de règles définies dans NeRoSim. Pour améliorer le système, les concepteurs du système espèrent introduire de nouvelles informations sémantiques pour nourrir le système et optimiser l'utilisation de solveurs au regard de nouveaux travaux.

        \subsubsection{FBK-HLT-NLP}

Magnolini et al. \cite{magnolini} proposent une approche multitâche en apprentissage profond. Pour chaque sous-tâche -prédiction de l’alignement au niveau des segments, du type de relation pour l’alignement et du score de similarité- ils utilisent un modèle de classification qui consiste en un unique perceptron multicouche. Le système met à profit 245 caractéristiques (linguistiques, embedding de mots, similarités de segments, etc.) toutes les mêmes quelle que soit la tâche.
Leur système tire parti d'un ensemble d'apprentissage plus important avec des données de domaines différents, ce qui lui confère l’avantage d’être extensible et évolutif. Il peut aussi adopter d’autres fonctionnalités visant à améliorer la précision.
L'étiquetage des types de relation entre les segments nécessite un nombre de classe important, rendant cette sous-tâche la plus difficile pour leur système.
En outre, la comparaison entre le classement effectué à partir des phrases segmentées et brute montre que le système ne bénéficie pas de paires de phrases déjà découpées.

        \subsubsection{IISCNLP}
 Les auteurs du système IISCNLP \cite{tekumalla} proposent un algorithme d’alignement multiple : iMATCH. Il est basé sur de la programmation linéaire en nombre entier et un alignement monolingue au niveau des segments. Tout d’abord, un segment \og gold \fg{} est utilisé. Si aucun n’est donné, la tâche est passée à \textit{OpenNLP Chunk} et \textit{Standford-core-nlp}. Ils utilisent ensuite une forêt d'arbres décisionnels \og one-vs-rest \fg{}. Les ponctuations et espaces inutiles sont retirés, les unicodes sont convertis au format ASCII et une normalisation est effectuée puis des caractéristiques sont extraites pour la classification. Leur normalisation est effectuée avant l’entraînement et la prédiction. Enfin, le classifieur qui prédit le score utilise une autre forêt d'arbres décisionnels \og one-vs-rest \fg{}. Chaque score est considéré comme une classe entre 0 et 1 où 0 signifie que les segments ne sont pas alignés. L’inconvénient du système est qu’il est soumis à la qualité des segments. Elle a un grand impacte sur l’alignement et donc sur le score final. Dans la plupart des cas, l’algorithme prédit le meilleur score d’alignement. Cependant, il bénéficierait d’autres caractéristiques qui améliorent la précision de la classification. Des techniques d’alignements simultanés pourraient aussi augmenter ses performances.

    \subsection{Baseline}

    Dans cette section, nous décrivons les différentes briques du système baseline que nous avons implémenter afin de résoudre notre tâche.

    \subsubsection{Embedding de mots et création de segments}
 Afin de réaliser la segmentation des phrases, nous avons créé un modèle afin de prédire et délimiter les unités de sens dans une phrase. À l’aide de ce modèle, nous cherchons à réaliser l'encodage BIO d’une phrase, c’est-à-dire prédire un label pour chaque mot de la phrase parmi ‘B’ (Begin), ‘I’ (Inside) ou ‘O’ (Outside) ; ces significations faisant référence à l’appartenance du mot à une unité de sens. Nous avons fait le choix d’un modèle récursif de type \og Simple RNN \fg{}. Les étiquettes nous permettent ensuite de délimiter les segments de la phrase avant de passer à l’étape de leur alignement.

Les données en entrée du réseau récurrent correspondent à des représentations vectorielles (issues d’une couche d’embeddings de GloVe) des mots d’une phrase, initialement tokenisés. Les étiquettes utilisés pour l'entraînement correspondent aux représentations \og one-hot  \fg{} des étiquettes BIO (encodés 0, 1, 2) de chacun des mots des phrases déjà segmentées mises à disposition dans le set de données du concours SemEval.

\paragraph{POS-tagging}

Dans une optique d’amélioration de notre segmentation et de développement d'un modèle multimodal, nous avons pensé que l’ajout d’un \og POS-tagging \fg{} aux caractéristiques d’entrée de notre modèle pourrait être intéressant. Nous avons donc utilisé l’API \textit{NLTK} pour effectuer un étiquetage automatique à partir des phrases tokenisées de la base de données. Ces nouvelles caractéristiques ne sont pas encore utilisées dans notre modèle, mais sont prêtes si besoin.

\subsubsection{Alignement des segments}

En s’inspirant des modèles de Banjade et al. \cite{banjade}  \cite{banjadeautre}, nous utilisons la méthode de Kuhn-Munkres pour optimiser l’alignement entre les mots puis l’alignement entre les segments et obtenir une similarité globale maximale. La similarité d’un segment ou d’une phrase est calculée en faisant la somme des similarités des éléments le constituant une fois ces derniers alignés de manière optimale. Pour cela, nous utilisons la fonction \og linear\_sum\_assignment \fg{} de la bibliothèque \textit{scipy.optimize}. Cette fonction prend en entrée une matrice M telle que M[i][j] correspond à la similarité de l’élément i du 1er segment ou phrase et de l’élément j du 2nd segment ou phrase et renvoie la combinaison de coefficients des deux segments ou phrases optimisant la similarité globale. On utilise tout d’abord cette fonction sur les segments 2 par 2. On cherche donc à aligner les mots de ces 2 segments de manière optimale pour déterminer leur similarité.

 On remplit la matrice M en calculant la similarité entre deux mots avec la formule :
sim(a, b) = a.ba*b avec a.b le produit scalaire entre a et b et |a| et |b| les normes de a et de b. Une fois la combinaison des coefficients optimaux renvoyée par la fonction \og linear\_sum\_assignment \fg{}, on peut calculer la similarité entre les deux comme la somme des similarités mot à mot. On utilise ensuite la fonction \og linear\_sum\_assignment \fg{} sur deux phrases. On cherche cette fois-ci à aligner les segments de ces deux phrases de manière optimale et d’obtenir un score de similarité entre 0 et 5 pour des segments alignés. L’étape ci-dessus nous permet de remplir la matrice M’ telle que M’[i][j] correspond à la similarité entre le segment i de la phrase 1 et le segment j de la phrase 2. Nous obtenons en sortie de la fonction la combinaison des coefficients optimaux ce qui nous permet de calculer un score de similarité entre deux segments alignés. Pour obtenir un score entre 0 et 5, on peut effectuer un \og minmaxscaling \fg{} sur les coefficients de similarités des segments alignés des deux phrases puis multiplier les valeurs obtenues par 5.

N.B. : si les matrices M et M’ ont plus de lignes que de colonnes alors certaines combinaisons ne seront pas testées pour trouver la solution optimale.
Il faut donc faire attention à ce que le premier argument de la fonction \og linear\_sum\_assignment \fg{} soit toujours l’élément de plus petite taille.

    \subsection{À suivre...}
     Ce qui est difficile, c’est de prendre en compte la variabilité dans les façons d’exprimer des informations dans des phrases similaires. Cette tâche date d’avant l’adoption généralisée de modèles neuronaux comme BERT. Dans un second temps, nous proposerons donc une solution qui met à profit entre autres les embedding et tokenizer mis à disposition dans les librairies transformers.

    \printbibliography
\end{document}